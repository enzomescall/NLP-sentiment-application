{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yoy9hla0dc4W"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEQj8UyUdc4Z",
    "outputId": "cf7562e1-bc2a-4690-84c0-b241d34d61e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tweet-preprocessor in /home/enzo/.local/lib/python3.10/site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "G-4AHU0adc4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 18:52:35.508596: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-04 18:52:35.509966: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-04 18:52:35.536803: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-04 18:52:35.537374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 18:52:35.951935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Flatten,Embedding,Bidirectional,LSTM,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "import os\n",
    "import preprocessor as p\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iJlOnPWwdc4e",
    "outputId": "dd898e86-dafe-4304-97be-73814397749f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/enzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/enzo/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5Fg0MbKdc4f"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "id": "42juEW1Kdc4g",
    "outputId": "b84f2ed8-2457-49cf-9451-f46033bb27c3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Biden_No_Retweet_Full_Text.csv\")\n",
    "df2 = pd.read_csv(\"Trump_No_Retweet_Full_Text.csv\")\n",
    "\n",
    "# Dataset is now stored in a Pandas Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uZUors84dc4h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15098 entries, 0 to 15097\n",
      "Data columns (total 11 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Date       15098 non-null  object\n",
      " 1   Tweet_id   15098 non-null  int64 \n",
      " 2   Verified   15098 non-null  bool  \n",
      " 3   Tweet      15098 non-null  object\n",
      " 4   User       15098 non-null  object\n",
      " 5   Location   11032 non-null  object\n",
      " 6   Source     15098 non-null  object\n",
      " 7   Likes      15098 non-null  int64 \n",
      " 8   Followers  15098 non-null  int64 \n",
      " 9   Following  15098 non-null  int64 \n",
      " 10  Retweets   15098 non-null  int64 \n",
      "dtypes: bool(1), int64(5), object(5)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8UrqGs_Ddc4j"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>User</th>\n",
       "      <th>Location</th>\n",
       "      <th>Source</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>Retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-21 23:59:43</td>\n",
       "      <td>1285726179907993601</td>\n",
       "      <td>False</td>\n",
       "      <td>@JoeBiden VP Biden I wish you wouldn't debate ...</td>\n",
       "      <td>BballmomEjZay</td>\n",
       "      <td>United States</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-21 23:59:27</td>\n",
       "      <td>1285726110513344520</td>\n",
       "      <td>False</td>\n",
       "      <td>#GeorgeWill , itâ€™s so sad you wake up everyday...</td>\n",
       "      <td>TalbotMac</td>\n",
       "      <td>East Aurora, NY</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>1554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-21 23:59:24</td>\n",
       "      <td>1285726099239055361</td>\n",
       "      <td>False</td>\n",
       "      <td>Question:\\nIf @JoeBiden doesnâ€™t pick a woman o...</td>\n",
       "      <td>bk_middleclass</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>1294</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-21 23:58:47</td>\n",
       "      <td>1285725945849151490</td>\n",
       "      <td>False</td>\n",
       "      <td>Right? ðŸ¤£ðŸ¤£ðŸ¤£ #Biden formally implicated in #Ukra...</td>\n",
       "      <td>MMorganBlair</td>\n",
       "      <td>United States</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>2476</td>\n",
       "      <td>3334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-21 23:58:02</td>\n",
       "      <td>1285725754961965056</td>\n",
       "      <td>False</td>\n",
       "      <td>These idiots let Trump do anything he wants. W...</td>\n",
       "      <td>realfacade1</td>\n",
       "      <td>Purgatory</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>2764</td>\n",
       "      <td>3799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-07-21 23:57:22</td>\n",
       "      <td>1285725587089362946</td>\n",
       "      <td>False</td>\n",
       "      <td>How could #Biden be +4 in #Ohio and +3 in #Pen...</td>\n",
       "      <td>bradpomerance</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>2722</td>\n",
       "      <td>1406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-07-21 23:56:58</td>\n",
       "      <td>1285725486749032449</td>\n",
       "      <td>False</td>\n",
       "      <td>@mamendoza480 There was never teaching any rel...</td>\n",
       "      <td>UsecommonSentz</td>\n",
       "      <td>United States</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-07-21 23:56:55</td>\n",
       "      <td>1285725476779102209</td>\n",
       "      <td>False</td>\n",
       "      <td>@chick_right @MSNBC @JoeNBC In your dreams @ch...</td>\n",
       "      <td>amauney28</td>\n",
       "      <td>Maryland, USA</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-07-21 23:56:19</td>\n",
       "      <td>1285725322399420416</td>\n",
       "      <td>False</td>\n",
       "      <td>Joy is on a one woman mission to expose #45 fo...</td>\n",
       "      <td>JanetThoma</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>0</td>\n",
       "      <td>2617</td>\n",
       "      <td>4989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-07-21 23:56:05</td>\n",
       "      <td>1285725266065719296</td>\n",
       "      <td>False</td>\n",
       "      <td>I slept better with OBAMA and BIDEN \\nnow JOE ...</td>\n",
       "      <td>RealMiddleClass</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1</td>\n",
       "      <td>375</td>\n",
       "      <td>815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date             Tweet_id  Verified  \\\n",
       "0  2020-07-21 23:59:43  1285726179907993601     False   \n",
       "1  2020-07-21 23:59:27  1285726110513344520     False   \n",
       "2  2020-07-21 23:59:24  1285726099239055361     False   \n",
       "3  2020-07-21 23:58:47  1285725945849151490     False   \n",
       "4  2020-07-21 23:58:02  1285725754961965056     False   \n",
       "5  2020-07-21 23:57:22  1285725587089362946     False   \n",
       "6  2020-07-21 23:56:58  1285725486749032449     False   \n",
       "7  2020-07-21 23:56:55  1285725476779102209     False   \n",
       "8  2020-07-21 23:56:19  1285725322399420416     False   \n",
       "9  2020-07-21 23:56:05  1285725266065719296     False   \n",
       "\n",
       "                                               Tweet             User  \\\n",
       "0  @JoeBiden VP Biden I wish you wouldn't debate ...    BballmomEjZay   \n",
       "1  #GeorgeWill , itâ€™s so sad you wake up everyday...        TalbotMac   \n",
       "2  Question:\\nIf @JoeBiden doesnâ€™t pick a woman o...   bk_middleclass   \n",
       "3  Right? ðŸ¤£ðŸ¤£ðŸ¤£ #Biden formally implicated in #Ukra...     MMorganBlair   \n",
       "4  These idiots let Trump do anything he wants. W...      realfacade1   \n",
       "5  How could #Biden be +4 in #Ohio and +3 in #Pen...    bradpomerance   \n",
       "6  @mamendoza480 There was never teaching any rel...   UsecommonSentz   \n",
       "7  @chick_right @MSNBC @JoeNBC In your dreams @ch...        amauney28   \n",
       "8  Joy is on a one woman mission to expose #45 fo...       JanetThoma   \n",
       "9  I slept better with OBAMA and BIDEN \\nnow JOE ...  RealMiddleClass   \n",
       "\n",
       "          Location               Source  Likes  Followers  Following  Retweets  \n",
       "0    United States  Twitter for Android      0         54        192         0  \n",
       "1  East Aurora, NY   Twitter for iPhone      0        882       1554         0  \n",
       "2    Nashville, TN   Twitter for iPhone      0       1294       1213         0  \n",
       "3    United States   Twitter for iPhone      1       2476       3334         1  \n",
       "4       Purgatory   Twitter for Android      0       2764       3799         0  \n",
       "5      Los Angeles   Twitter for iPhone      0       2722       1406         0  \n",
       "6    United States      Twitter Web App      0        403        781         0  \n",
       "7    Maryland, USA   Twitter for iPhone      0         78        958         0  \n",
       "8          Chicago      Twitter Web App      0       2617       4989         0  \n",
       "9  Los Angeles, CA      Twitter Web App      1        375        815         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LTRsN7Kfdc4m"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset = \"Tweet\", keep = \"first\",inplace = True,ignore_index = True) #Removing duplicates Biden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f0pKjn9dc4n"
   },
   "source": [
    "#### Cleaning Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fdTAzEUfdc4o"
   },
   "outputs": [],
   "source": [
    "tweet_list = []\n",
    "for x in df[\"Tweet\"]:\n",
    "    tweet_list.append(p.clean(x)) #Cleaning tweets (Removes URLs, Hashtags, Mentions, Reserved Words (RT,FAV) Emojis, Smileys) and appending to a list\n",
    "    \n",
    "tweet_list = [re.sub('[^a-zA-Z]', ' ',i) for i in tweet_list] #Removing punctuatuons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UM5XDJnadc4p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Before----\n",
      "Right? ðŸ¤£ðŸ¤£ðŸ¤£ #Biden formally implicated in #Ukraine scandal @ChanelRion reported this afternoon \n",
      " #Burisma https://t.co/B13j0IR6er\n",
      "----After----\n",
      "Right  formally implicated in scandal reported this afternoon\n"
     ]
    }
   ],
   "source": [
    "print(\"----Before----\")\n",
    "print(df[\"Tweet\"][3])\n",
    "\n",
    "print(\"----After----\")\n",
    "print(tweet_list[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gxnku0mPdc4q"
   },
   "source": [
    "#### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0fTVtnuQdc4r"
   },
   "outputs": [],
   "source": [
    "clean_tweets = []\n",
    "for tweet in tweet_list: \n",
    "        for word in set(stopwords.words(\"english\")):\n",
    "            token = \" \"+word+\" \"\n",
    "            tweet = tweet.replace(token, \" \")\n",
    "        clean_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KJ-bQstpdc4r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VP Biden I wish debate Trump unless  Debate Trump shows taxesDebate Tells Putin stop killing soldiersDebate Put sanctions Putin election hacks amp  I wish publicly challenge   Rice',\n",
       " '  sad wake everyday forgetting YOU George Will    like Swampers badly need disinfect  Youre new breed SenileElites  Same man plan vote for',\n",
       " 'Question If doesnt pick woman color  would black community hold ',\n",
       " 'Right  formally implicated scandal reported afternoon',\n",
       " 'These idiots let Trump anything wants  When Biden gets elected  I want hear word  I hope come like ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKaYFxuAdc4s"
   },
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "AQp7qj59dc4t"
   },
   "outputs": [],
   "source": [
    "stemmed = []\n",
    "for word in clean_tweets:\n",
    "    stemmed.append(PorterStemmer().stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZAAwX01qdc4u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vp biden i wish debate trump unless  debate trump shows taxesdebate tells putin stop killing soldiersdebate put sanctions putin election hacks amp  i wish publicly challenge   ric',\n",
       " '  sad wake everyday forgetting you george will    like swampers badly need disinfect  youre new breed senileelites  same man plan vote for',\n",
       " 'question if doesnt pick woman color  would black community hold ',\n",
       " 'right  formally implicated scandal reported afternoon',\n",
       " 'these idiots let trump anything wants  when biden gets elected  i want hear word  i hope come like ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8AR-oVKAdc4v"
   },
   "outputs": [],
   "source": [
    "df[\"Processed\"] = stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy_z6d0wdc4v"
   },
   "source": [
    "### Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "npGn9K9Cdc4v"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>americans</th>\n",
       "      <th>amp</th>\n",
       "      <th>and</th>\n",
       "      <th>another</th>\n",
       "      <th>anyone</th>\n",
       "      <th>...</th>\n",
       "      <th>will</th>\n",
       "      <th>win</th>\n",
       "      <th>wins</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290424</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387464</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.299367</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.530189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   all  already  also   america  american  americans       amp  and  another  \\\n",
       "0  0.0      0.0   0.0  0.000000       0.0        0.0  0.290424  0.0      0.0   \n",
       "1  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "2  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "3  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "4  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "5  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "6  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "7  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "8  0.0      0.0   0.0  0.000000       0.0        0.0  0.000000  0.0      0.0   \n",
       "9  0.0      0.0   0.0  0.284088       0.0        0.0  0.000000  0.0      0.0   \n",
       "\n",
       "     anyone  ...      will  win  wins  work  world     would  years  yes  \\\n",
       "0  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "1  0.000000  ...  0.387464  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "2  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.516294    0.0  0.0   \n",
       "3  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "4  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "5  0.530189  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "6  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "7  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "8  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "9  0.000000  ...  0.000000  0.0   0.0   0.0    0.0  0.000000    0.0  0.0   \n",
       "\n",
       "        you  your  \n",
       "0  0.000000   0.0  \n",
       "1  0.299367   0.0  \n",
       "2  0.000000   0.0  \n",
       "3  0.000000   0.0  \n",
       "4  0.000000   0.0  \n",
       "5  0.000000   0.0  \n",
       "6  0.000000   0.0  \n",
       "7  0.000000   0.0  \n",
       "8  0.000000   0.0  \n",
       "9  0.000000   0.0  \n",
       "\n",
       "[10 rows x 150 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vector = TfidfVectorizer(ngram_range=(1,1), max_features=150).fit(df[\"Processed\"]) \n",
    "\n",
    "trans = vector.transform(df[\"Processed\"])  # Transforming the vectorizer\n",
    "\n",
    "df_vect=pd.DataFrame(trans.toarray(), columns=vector.get_feature_names_out()) # Converting to DataFrame\n",
    "\n",
    "df_vect.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpgzJ1ZBdc4w"
   },
   "source": [
    "### Sentiment Analysis using TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VTiX8YNQdc4x"
   },
   "outputs": [],
   "source": [
    "pol = []\n",
    "\n",
    "for tweet in df[\"Processed\"]:\n",
    "    blob = TextBlob(tweet)\n",
    "    pol.append(blob.sentiment.polarity)\n",
    "df['Polarity']=pol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "hHMHhWpmdc4y"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      United States\n",
       "1    East Aurora, NY\n",
       "2      Nashville, TN\n",
       "3      United States\n",
       "4         Purgatory \n",
       "5        Los Angeles\n",
       "6      United States\n",
       "7      Maryland, USA\n",
       "8            Chicago\n",
       "9    Los Angeles, CA\n",
       "Name: Location, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Location'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkT6kWFCdc4y"
   },
   "source": [
    "#### Segregating into Positive, Negative and Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "478VUpqWs63x"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet_id</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>User</th>\n",
       "      <th>Location</th>\n",
       "      <th>Source</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Processed</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>State_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-21 23:59:43</td>\n",
       "      <td>1285726179907993601</td>\n",
       "      <td>False</td>\n",
       "      <td>@JoeBiden VP Biden I wish you wouldn't debate ...</td>\n",
       "      <td>BballmomEjZay</td>\n",
       "      <td>United States</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>vp biden i wish debate trump unless  debate tr...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-21 23:59:27</td>\n",
       "      <td>1285726110513344520</td>\n",
       "      <td>False</td>\n",
       "      <td>#GeorgeWill , itâ€™s so sad you wake up everyday...</td>\n",
       "      <td>TalbotMac</td>\n",
       "      <td>East Aurora, NY</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>1554</td>\n",
       "      <td>0</td>\n",
       "      <td>sad wake everyday forgetting you george will...</td>\n",
       "      <td>-0.252727</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-21 23:59:24</td>\n",
       "      <td>1285726099239055361</td>\n",
       "      <td>False</td>\n",
       "      <td>Question:\\nIf @JoeBiden doesnâ€™t pick a woman o...</td>\n",
       "      <td>bk_middleclass</td>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>0</td>\n",
       "      <td>1294</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "      <td>question if doesnt pick woman color  would bla...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-21 23:58:47</td>\n",
       "      <td>1285725945849151490</td>\n",
       "      <td>False</td>\n",
       "      <td>Right? ðŸ¤£ðŸ¤£ðŸ¤£ #Biden formally implicated in #Ukra...</td>\n",
       "      <td>MMorganBlair</td>\n",
       "      <td>United States</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1</td>\n",
       "      <td>2476</td>\n",
       "      <td>3334</td>\n",
       "      <td>1</td>\n",
       "      <td>right  formally implicated scandal reported af...</td>\n",
       "      <td>-0.057143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-21 23:58:02</td>\n",
       "      <td>1285725754961965056</td>\n",
       "      <td>False</td>\n",
       "      <td>These idiots let Trump do anything he wants. W...</td>\n",
       "      <td>realfacade1</td>\n",
       "      <td>Purgatory</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>0</td>\n",
       "      <td>2764</td>\n",
       "      <td>3799</td>\n",
       "      <td>0</td>\n",
       "      <td>these idiots let trump anything wants  when bi...</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date             Tweet_id  Verified  \\\n",
       "0  2020-07-21 23:59:43  1285726179907993601     False   \n",
       "1  2020-07-21 23:59:27  1285726110513344520     False   \n",
       "2  2020-07-21 23:59:24  1285726099239055361     False   \n",
       "3  2020-07-21 23:58:47  1285725945849151490     False   \n",
       "4  2020-07-21 23:58:02  1285725754961965056     False   \n",
       "\n",
       "                                               Tweet            User  \\\n",
       "0  @JoeBiden VP Biden I wish you wouldn't debate ...   BballmomEjZay   \n",
       "1  #GeorgeWill , itâ€™s so sad you wake up everyday...       TalbotMac   \n",
       "2  Question:\\nIf @JoeBiden doesnâ€™t pick a woman o...  bk_middleclass   \n",
       "3  Right? ðŸ¤£ðŸ¤£ðŸ¤£ #Biden formally implicated in #Ukra...    MMorganBlair   \n",
       "4  These idiots let Trump do anything he wants. W...     realfacade1   \n",
       "\n",
       "          Location               Source  Likes  Followers  Following  \\\n",
       "0    United States  Twitter for Android      0         54        192   \n",
       "1  East Aurora, NY   Twitter for iPhone      0        882       1554   \n",
       "2    Nashville, TN   Twitter for iPhone      0       1294       1213   \n",
       "3    United States   Twitter for iPhone      1       2476       3334   \n",
       "4       Purgatory   Twitter for Android      0       2764       3799   \n",
       "\n",
       "   Retweets                                          Processed  Polarity  \\\n",
       "0         0  vp biden i wish debate trump unless  debate tr...  0.000000   \n",
       "1         0    sad wake everyday forgetting you george will... -0.252727   \n",
       "2         0  question if doesnt pick woman color  would bla... -0.166667   \n",
       "3         1  right  formally implicated scandal reported af... -0.057143   \n",
       "4         0  these idiots let trump anything wants  when bi... -0.300000   \n",
       "\n",
       "   State_Index  \n",
       "0          NaN  \n",
       "1         31.0  \n",
       "2         41.0  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a mapping of state names and abbreviations to their index in the 'states' list\n",
    "state_mapping = {\n",
    "    'Alabama': 0, 'AL': 0,\n",
    "    'Alaska': 1, 'AK': 1,\n",
    "    'Arizona': 2, 'AZ': 2,\n",
    "    'Arkansas': 3, 'AR': 3,\n",
    "    'California': 4, 'CA': 4,\n",
    "    'Colorado': 5, 'CO': 5,\n",
    "    'Connecticut': 6, 'CT': 6,\n",
    "    'Delaware': 7, 'DE': 7,\n",
    "    'Florida': 8, 'FL': 8,\n",
    "    'Georgia': 9, 'GA': 9,\n",
    "    'Hawaii': 10, 'HI': 10,\n",
    "    'Idaho': 11, 'ID': 11,\n",
    "    'Illinois': 12, 'IL': 12,\n",
    "    'Indiana': 13, 'IN': 13,\n",
    "    'Iowa': 14, 'IA': 14,\n",
    "    'Kansas': 15, 'KS': 15,\n",
    "    'Kentucky': 16, 'KY': 16,\n",
    "    'Louisiana': 17, 'LA': 17,\n",
    "    'Maine': 18, 'ME': 18,\n",
    "    'Maryland': 19, 'MD': 19,\n",
    "    'Massachusetts': 20, 'MA': 20,\n",
    "    'Michigan': 21, 'MI': 21,\n",
    "    'Minnesota': 22, 'MN': 22,\n",
    "    'Mississippi': 23, 'MS': 23,\n",
    "    'Missouri': 24, 'MO': 24,\n",
    "    'Montana': 25, 'MT': 25,\n",
    "    'Nebraska': 26, 'NE': 26,\n",
    "    'Nevada': 27, 'NV': 27,\n",
    "    'New Hampshire': 28, 'NH': 28,\n",
    "    'New Jersey': 29, 'NJ': 29,\n",
    "    'New Mexico': 30, 'NM': 30,\n",
    "    'New York': 31, 'NY': 31,\n",
    "    'North Carolina': 32, 'NC': 32,\n",
    "    'North Dakota': 33, 'ND': 33,\n",
    "    'Ohio': 34, 'OH': 34,\n",
    "    'Oklahoma': 35, 'OK': 35,\n",
    "    'Oregon': 36, 'OR': 36,\n",
    "    'Pennsylvania': 37, 'PA': 37,\n",
    "    'Rhode Island': 38, 'RI': 38,\n",
    "    'South Carolina': 39, 'SC': 39,\n",
    "    'South Dakota': 40, 'SD': 40,\n",
    "    'Tennessee': 41, 'TN': 41,\n",
    "    'Texas': 42, 'TX': 42,\n",
    "    'Utah': 43, 'UT': 43,\n",
    "    'Vermont': 44, 'VT': 44,\n",
    "    'Virginia': 45, 'VA': 45,\n",
    "    'Washington': 46, 'WA': 46,\n",
    "    'West Virginia': 47, 'WV': 47,\n",
    "    'Wisconsin': 48, 'WI': 48,\n",
    "    'Wyoming': 49, 'WY': 49,\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the 'states' list with zeros\n",
    "states = [0] * 50\n",
    "\n",
    "# Define a function to categorize the location\n",
    "def categorize_location(location, state_mapping):\n",
    "    if pd.isna(location):\n",
    "        return None\n",
    "    for key, index in state_mapping.items():\n",
    "        pattern = r'\\b(?:{})\\b'.format(re.escape(key))\n",
    "        if re.search(pattern, location, re.IGNORECASE):\n",
    "            return index\n",
    "    return None\n",
    "\n",
    "# Apply the categorize_location function to the 'Location' column and store the results in a new column\n",
    "df['State_Index'] = df['Location'].apply(categorize_location, args=(state_mapping,))\n",
    "\n",
    "# Update the 'states' list with the count of tweets from each state\n",
    "for index in df['State_Index'].dropna().astype(int):\n",
    "    states[index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "br3cue-vy0DT"
   },
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store sentiment counts, total polarity, and tweet counts for each state\n",
    "sentiment_counts = {index: {'positive': 0, 'negative': 0, 'neutral': 0} for index in range(50)}\n",
    "total_polarity = {index: 0 for index in range(50)}\n",
    "tweet_counts = {index: 0 for index in range(50)}\n",
    "\n",
    "# Iterate through the DataFrame rows and update sentiment counts, total polarity, and tweet counts for each state\n",
    "for _, row in df.iterrows():\n",
    "    if pd.isna(row['State_Index']):\n",
    "        continue\n",
    "    state_index = int(row['State_Index'])\n",
    "    polarity = row['Polarity']\n",
    "    \n",
    "    if polarity > 0:\n",
    "        sentiment_counts[state_index]['positive'] += 1\n",
    "    elif polarity < 0:\n",
    "        sentiment_counts[state_index]['negative'] += 1\n",
    "    else:\n",
    "        sentiment_counts[state_index]['neutral'] += 1\n",
    "\n",
    "    total_polarity[state_index] += polarity\n",
    "    tweet_counts[state_index] += 1\n",
    "\n",
    "# Calculate the mean polarity for each state\n",
    "mean_polarity = {index: total_polarity[index] / tweet_counts[index] if tweet_counts[index] > 0 else 0 for index in range(50)}\n",
    "\n",
    "# Define a function to assign sentiment based on polarity\n",
    "def assign_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return \"Positive\"\n",
    "    elif polarity < 0:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Assign sentiment to each tweet using the assign_sentiment function\n",
    "df['Sentiment'] = df['Polarity'].apply(assign_sentiment)\n",
    "\n",
    "# Convert the mean_polarity and sentiment_counts dictionaries to have state names as keys instead of indices\n",
    "state_names = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'Florida',\n",
    "    'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine',\n",
    "    'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
    "    'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma',\n",
    "    'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont',\n",
    "    'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]\n",
    "\n",
    "mean_polarity_by_state = {state_names[index]: mean_polarity[index] for index in range(50)}\n",
    "sentiment_counts_by_state = {state_names[index]: sentiment_counts[index] for index in range(50)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "C80rhMwMz6-v"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Alabama': -0.008569594757094746,\n",
       " 'Alaska': 0.007282913165266107,\n",
       " 'Arizona': 0.05137708982454205,\n",
       " 'Arkansas': -0.02490842490842491,\n",
       " 'California': 0.06572405363909169,\n",
       " 'Colorado': 0.04875727792878956,\n",
       " 'Connecticut': 0.035447845804988665,\n",
       " 'Delaware': -0.03474258275394639,\n",
       " 'Florida': 0.05395323713605328,\n",
       " 'Georgia': 0.09011241238919811,\n",
       " 'Hawaii': 0.035955086580086566,\n",
       " 'Idaho': 0.01410984848484848,\n",
       " 'Illinois': 0.024853509384025807,\n",
       " 'Indiana': 0.037442149167509375,\n",
       " 'Iowa': 0.14856702586541298,\n",
       " 'Kansas': 0.002881708238851096,\n",
       " 'Kentucky': 0.0205764163372859,\n",
       " 'Louisiana': 0.05482055042910307,\n",
       " 'Maine': 0.16753826878826877,\n",
       " 'Maryland': 0.045851222782192926,\n",
       " 'Massachusetts': 0.061930990340505296,\n",
       " 'Michigan': 0.05762365362811793,\n",
       " 'Minnesota': 0.01831525514715171,\n",
       " 'Mississippi': -0.019449206349206327,\n",
       " 'Missouri': 0.09842136579149569,\n",
       " 'Montana': 0.020436507936507937,\n",
       " 'Nebraska': 0.0517625231910946,\n",
       " 'Nevada': 0.030566836915521124,\n",
       " 'New Hampshire': -0.05762085137085137,\n",
       " 'New Jersey': 0.04088578441631876,\n",
       " 'New Mexico': 0.07492325855962219,\n",
       " 'New York': 0.05625815660947241,\n",
       " 'North Carolina': 0.03603515068180721,\n",
       " 'North Dakota': -0.016666666666666677,\n",
       " 'Ohio': 0.018080981936403617,\n",
       " 'Oklahoma': 0.10729627354627354,\n",
       " 'Oregon': 0.0610494131364667,\n",
       " 'Pennsylvania': 0.06216865399557706,\n",
       " 'Rhode Island': 0.014285714285714285,\n",
       " 'South Carolina': 0.03658293612415953,\n",
       " 'South Dakota': -0.10416666666666667,\n",
       " 'Tennessee': 0.014332010582010583,\n",
       " 'Texas': 0.07511343166011959,\n",
       " 'Utah': 0.04907407407407408,\n",
       " 'Vermont': 0.06515948963317385,\n",
       " 'Virginia': 0.022955980514942787,\n",
       " 'Washington': 0.09734030608186965,\n",
       " 'West Virginia': 0.19033333333333333,\n",
       " 'Wisconsin': 0.05282575757575758,\n",
       " 'Wyoming': 0.08742857142857142}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_polarity_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "gha9RDpuz7Xd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'positive': 21, 'negative': 17, 'neutral': 22},\n",
       " 1: {'positive': 5, 'negative': 3, 'neutral': 9},\n",
       " 2: {'positive': 65, 'negative': 41, 'neutral': 51},\n",
       " 3: {'positive': 4, 'negative': 2, 'neutral': 7},\n",
       " 4: {'positive': 300, 'negative': 168, 'neutral': 263},\n",
       " 5: {'positive': 58, 'negative': 30, 'neutral': 41},\n",
       " 6: {'positive': 9, 'negative': 9, 'neutral': 17},\n",
       " 7: {'positive': 11, 'negative': 11, 'neutral': 11},\n",
       " 8: {'positive': 189, 'negative': 105, 'neutral': 194},\n",
       " 9: {'positive': 52, 'negative': 18, 'neutral': 42},\n",
       " 10: {'positive': 9, 'negative': 6, 'neutral': 7},\n",
       " 11: {'positive': 4, 'negative': 1, 'neutral': 7},\n",
       " 12: {'positive': 84, 'negative': 72, 'neutral': 57},\n",
       " 13: {'positive': 81, 'negative': 72, 'neutral': 80},\n",
       " 14: {'positive': 22, 'negative': 4, 'neutral': 5},\n",
       " 15: {'positive': 8, 'negative': 6, 'neutral': 7},\n",
       " 16: {'positive': 13, 'negative': 12, 'neutral': 21},\n",
       " 17: {'positive': 17, 'negative': 8, 'neutral': 13},\n",
       " 18: {'positive': 18, 'negative': 2, 'neutral': 17},\n",
       " 19: {'positive': 30, 'negative': 16, 'neutral': 21},\n",
       " 20: {'positive': 52, 'negative': 31, 'neutral': 51},\n",
       " 21: {'positive': 48, 'negative': 27, 'neutral': 37},\n",
       " 22: {'positive': 21, 'negative': 14, 'neutral': 23},\n",
       " 23: {'positive': 10, 'negative': 9, 'neutral': 6},\n",
       " 24: {'positive': 41, 'negative': 12, 'neutral': 24},\n",
       " 25: {'positive': 3, 'negative': 2, 'neutral': 7},\n",
       " 26: {'positive': 6, 'negative': 3, 'neutral': 5},\n",
       " 27: {'positive': 31, 'negative': 22, 'neutral': 42},\n",
       " 28: {'positive': 3, 'negative': 4, 'neutral': 5},\n",
       " 29: {'positive': 88, 'negative': 55, 'neutral': 119},\n",
       " 30: {'positive': 10, 'negative': 5, 'neutral': 7},\n",
       " 31: {'positive': 197, 'negative': 105, 'neutral': 173},\n",
       " 32: {'positive': 51, 'negative': 36, 'neutral': 54},\n",
       " 33: {'positive': 3, 'negative': 2, 'neutral': 3},\n",
       " 34: {'positive': 33, 'negative': 22, 'neutral': 28},\n",
       " 35: {'positive': 22, 'negative': 6, 'neutral': 9},\n",
       " 36: {'positive': 39, 'negative': 24, 'neutral': 49},\n",
       " 37: {'positive': 67, 'negative': 38, 'neutral': 64},\n",
       " 38: {'positive': 2, 'negative': 2, 'neutral': 6},\n",
       " 39: {'positive': 18, 'negative': 14, 'neutral': 15},\n",
       " 40: {'positive': 0, 'negative': 1, 'neutral': 2},\n",
       " 41: {'positive': 19, 'negative': 20, 'neutral': 21},\n",
       " 42: {'positive': 146, 'negative': 70, 'neutral': 142},\n",
       " 43: {'positive': 6, 'negative': 6, 'neutral': 9},\n",
       " 44: {'positive': 9, 'negative': 6, 'neutral': 4},\n",
       " 45: {'positive': 65, 'negative': 46, 'neutral': 48},\n",
       " 46: {'positive': 179, 'negative': 73, 'neutral': 129},\n",
       " 47: {'positive': 4, 'negative': 1, 'neutral': 0},\n",
       " 48: {'positive': 23, 'negative': 9, 'neutral': 18},\n",
       " 49: {'positive': 2, 'negative': 2, 'neutral': 1}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_wtwRBQLdc4z"
   },
   "outputs": [],
   "source": [
    "positive ,negative, neutral = 0,0,0\n",
    "\n",
    "for polar in df[\"Polarity\"]:\n",
    "    if polar > 0:\n",
    "        positive += 1\n",
    "    elif polar < 0:\n",
    "        negative += 1\n",
    "    else:\n",
    "        neutral += 1\n",
    "        \n",
    "pol_list = []\n",
    "\n",
    "for x in pol:\n",
    "    if x>0:\n",
    "        pol_list.append(\"Positive\")\n",
    "    elif x<0:\n",
    "        pol_list.append(\"Negative\")\n",
    "    else:\n",
    "        pol_list.append(\"Neutral\")\n",
    "        \n",
    "df[\"Sentiment\"] = pol_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DfJtLYhrdc40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive : 6029\n",
      "Negative : 3608\n",
      "Neutral : 5409\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive :\",positive)\n",
    "print(\"Negative :\",negative)\n",
    "print(\"Neutral :\",neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "s6_4dr9ldc40"
   },
   "outputs": [],
   "source": [
    "sentences = list(df.Processed)\n",
    "labels = df.Sentiment.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9e2zZvwvRT7"
   },
   "source": [
    "### Same thing but for Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YtV49JO3vWiW"
   },
   "outputs": [],
   "source": [
    "df2.drop_duplicates(subset = \"Tweet\", keep = \"first\",inplace = True,ignore_index = True) #Removing duplicates Biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "2KlqxUjnveFk"
   },
   "outputs": [],
   "source": [
    "tweet_list = []\n",
    "for x in df2[\"Tweet\"]:\n",
    "    tweet_list.append(p.clean(x)) #Cleaning tweets (Removes URLs, Hashtags, Mentions, Reserved Words (RT,FAV) Emojis, Smileys) and appending to a list\n",
    "    \n",
    "tweet_list = [re.sub('[^a-zA-Z]', ' ',i) for i in tweet_list] #Removing punctuatuons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1SSlZHcSvl4U"
   },
   "outputs": [],
   "source": [
    "clean_tweets = []\n",
    "for tweet in tweet_list: \n",
    "        for word in set(stopwords.words(\"english\")):\n",
    "            token = \" \"+word+\" \"\n",
    "            tweet = tweet.replace(token, \" \")\n",
    "        clean_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o9tLXiIrvrGO"
   },
   "outputs": [],
   "source": [
    "stemmed = []\n",
    "for word in clean_tweets:\n",
    "    stemmed.append(PorterStemmer().stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "sNHjtwVHvtLI"
   },
   "outputs": [],
   "source": [
    "df2[\"Processed\"] = stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "eXUKz68Ev7UD"
   },
   "outputs": [],
   "source": [
    "vector2 = TfidfVectorizer(ngram_range=(1,1), max_features=150).fit(df2[\"Processed\"]) \n",
    "\n",
    "trans2 = vector2.transform(df2[\"Processed\"])  # Transforming the vectorizer\n",
    "\n",
    "df2_vect=pd.DataFrame(trans2.toarray(), columns=vector2.get_feature_names_out()) # Converting to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "pUhnh7VHwaFi"
   },
   "outputs": [],
   "source": [
    "pol = []\n",
    "\n",
    "for tweet in df2[\"Processed\"]:\n",
    "    blob = TextBlob(tweet)\n",
    "    pol.append(blob.sentiment.polarity)\n",
    "df2['Trump_Polarity']=pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7JXX4HNwaFj"
   },
   "source": [
    "#### Segregating into Positive, Negative and Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "pEd8W1fhwaFk"
   },
   "outputs": [],
   "source": [
    "# Apply the categorize_location function to the 'Location' column and store the results in a new column\n",
    "df2['State_Index'] = df2['Location'].apply(categorize_location, args=(state_mapping,))\n",
    "\n",
    "biden_states = states\n",
    "trump_states = [0]*50\n",
    "\n",
    "# Update the 'states' list with the count of tweets from each state\n",
    "for index in df2['State_Index'].dropna().astype(int):\n",
    "    trump_states[index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "7AcKqMyHwaFk"
   },
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store sentiment counts, total polarity, and tweet counts for each state\n",
    "trump_sentiment_counts = {index: {'trump positive': 0, 'trump negative': 0, 'trump neutral': 0} for index in range(50)}\n",
    "trump_total_polarity = {index: 0 for index in range(50)}\n",
    "trump_tweet_counts = {index: 0 for index in range(50)}\n",
    "\n",
    "# Iterate through the DataFrame rows and update sentiment counts, total polarity, and tweet counts for each state\n",
    "for _, row in df2.iterrows():\n",
    "    if pd.isna(row['State_Index']):\n",
    "        continue\n",
    "    state_index = int(row['State_Index'])\n",
    "    polarity = row['Trump_Polarity']\n",
    "    \n",
    "    if polarity > 0:\n",
    "        trump_sentiment_counts[state_index]['trump positive'] += 1\n",
    "    elif polarity < 0:\n",
    "        trump_sentiment_counts[state_index]['trump negative'] += 1\n",
    "    else:\n",
    "        trump_sentiment_counts[state_index]['trump neutral'] += 1\n",
    "\n",
    "    trump_total_polarity[state_index] += polarity\n",
    "    trump_tweet_counts[state_index] += 1\n",
    "\n",
    "# Calculate the mean polarity for each state\n",
    "trump_mean_polarity = {index: trump_total_polarity[index] / trump_tweet_counts[index] if trump_tweet_counts[index] > 0 else 0 for index in range(50)}\n",
    "\n",
    "# Assign sentiment to each tweet using the assign_sentiment function\n",
    "df2['Sentiment'] = df2['Polarity'].apply(assign_sentiment)\n",
    "\n",
    "# Convert the mean_polarity and sentiment_counts dictionaries to have state names as keys instead of indices\n",
    "trump_mean_polarity_by_state = {state_names[index]: trump_mean_polarity[index] for index in range(50)}\n",
    "trump_sentiment_counts_by_state = {state_names[index]: trump_sentiment_counts[index] for index in range(50)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "39SwmHUDwaFm"
   },
   "outputs": [],
   "source": [
    "positive ,negative, neutral = 0,0,0\n",
    "\n",
    "for polar in df2[\"Polarity\"]:\n",
    "    if polar > 0:\n",
    "        positive += 1\n",
    "    elif polar < 0:\n",
    "        negative += 1\n",
    "    else:\n",
    "        neutral += 1\n",
    "        \n",
    "pol_list = []\n",
    "\n",
    "for x in pol:\n",
    "    if x>0:\n",
    "        pol_list.append(\"Trump Positive\")\n",
    "    elif x<0:\n",
    "        pol_list.append(\"Trump Negative\")\n",
    "    else:\n",
    "        pol_list.append(\"Trump Neutral\")\n",
    "        \n",
    "df2[\"Sentiment\"] = pol_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_sentiment_count = pd.DataFrame.from_dict(sentiment_counts_by_state, orient='index').rename(columns={\n",
    "    \"positive\":\"biden positive\",\n",
    "    \"negative\":\"biden negative\",\n",
    "    \"neutral\":\"biden neutral\"\n",
    "})\n",
    "biden_mean_sentminent = pd.DataFrame.from_dict(mean_polarity_by_state, orient='index').rename(columns={0:\"biden mean\"})\n",
    "trump_sentiment_count = pd.DataFrame.from_dict(trump_sentiment_counts_by_state, orient='index')\n",
    "trump_mean_sentminent = pd.DataFrame.from_dict(trump_mean_polarity_by_state, orient='index').rename(columns={0:\"trump mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biden positive</th>\n",
       "      <th>biden negative</th>\n",
       "      <th>biden neutral</th>\n",
       "      <th>Biden mean</th>\n",
       "      <th>trump positive</th>\n",
       "      <th>trump negative</th>\n",
       "      <th>trump neutral</th>\n",
       "      <th>trump mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.008570</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.155742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.007283</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.053571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "      <td>51</td>\n",
       "      <td>0.051377</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0.006855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.024908</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.067542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>300</td>\n",
       "      <td>168</td>\n",
       "      <td>263</td>\n",
       "      <td>0.065724</td>\n",
       "      <td>362</td>\n",
       "      <td>253</td>\n",
       "      <td>367</td>\n",
       "      <td>0.035545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            biden positive  biden negative  biden neutral  Biden mean  \\\n",
       "Alabama                 21              17             22   -0.008570   \n",
       "Alaska                   5               3              9    0.007283   \n",
       "Arizona                 65              41             51    0.051377   \n",
       "Arkansas                 4               2              7   -0.024908   \n",
       "California             300             168            263    0.065724   \n",
       "\n",
       "            trump positive  trump negative  trump neutral  trump mean  \n",
       "Alabama                  9               2              4    0.155742  \n",
       "Alaska                   1               1              5    0.053571  \n",
       "Arizona                 31              35             35    0.006855  \n",
       "Arkansas                 3               4              2   -0.067542  \n",
       "California             362             253            367    0.035545  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = biden_sentiment_count.join(biden_mean_sentminent).join(trump_sentiment_count).join(trump_mean_sentminent)\n",
    "\n",
    "output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('baseline_data.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
